- name: Deploy AI stack
  hosts: manager:&cloud
  vars:
    ansible_python_interpreter: /root/.ansible_venv/bin/python
  vars_files:
    - ../vault.yaml
  tasks:
    - name: Create pgvector_data volume
      community.docker.docker_volume:
        name: pgvector_data

    - name: Create librechat_images volume
      community.docker.docker_volume:
        name: librechat_images

    - name: Create mongodb_data volume
      community.docker.docker_volume:
        name: mongodb_data

    - name: Create meili_data volume
      community.docker.docker_volume:
        name: meili_data

    - name: Create ai network
      community.docker.docker_network:
        name: ai
        driver: overlay

    - name: Create AI stack directory
      file:
        path: /root/stacks/ai
        state: directory

    - name: Copy compose file to AI stack directory
      copy:
        src: ../stacks/ai/compose.yaml
        dest: /root/stacks/ai/compose.yaml

    - name: Create librechat.yaml file
      copy:
        content: |
          version: 1.1.6

          cache: true

          speech:
            stt:
              openai:
                apiKey: '{{ api_keys.openai }}'
                model: 'whisper-1'
            tts:
              openai:
                apiKey: '{{ api_keys.openai }}'
                model: 'tts-1'
                voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']

        dest: /root/stacks/ai/librechat.yaml

    - name: Create .env file
      copy:
        content: |
          HOST=ai.rusanov.cloud
          PORT=3080

          DOMAIN_CLIENT=https://ai.rusanov.cloud
          DOMAIN_SERVER=https://ai.rusanov.cloud

          NO_INDEX=true

          #===============#
          # JSON Logging  #
          #===============#

          # Use when process console logs in cloud deployment like GCP/AWS
          CONSOLE_JSON=false

          #===============#
          # Debug Logging #
          #===============#

          DEBUG_LOGGING=true
          DEBUG_CONSOLE=true

          #=============#
          # Permissions #
          #=============#

          # UID=1000
          # GID=1000

          #===============#
          # Configuration #
          #===============#
          # Use an absolute path, a relative path, or a URL

          # CONFIG_PATH="/alternative/path/to/librechat.yaml"

          #===================================================#
          #                     Endpoints                     #
          #===================================================#

          ENDPOINTS=openAI,assistants,gptPlugins
          # ,azureOpenAI,bingAI,google,gptPlugins,anthropic

          # PROXY=

          #===================================#
          # Known Endpoints - librechat.yaml  #
          #===================================#
          # https://www.librechat.ai/docs/configuration/librechat_yaml/ai_endpoints

          # ANYSCALE_API_KEY=
          # APIPIE_API_KEY=
          # COHERE_API_KEY=
          # DEEPSEEK_API_KEY=
          # DATABRICKS_API_KEY=
          # FIREWORKS_API_KEY=
          # GROQ_API_KEY=
          # HUGGINGFACE_TOKEN=
          # MISTRAL_API_KEY=
          # OPENROUTER_KEY=
          # PERPLEXITY_API_KEY=
          # SHUTTLEAI_API_KEY=
          # TOGETHERAI_API_KEY=
          # UNIFY_API_KEY=

          #============#
          # Anthropic  #
          #============#

          # ANTHROPIC_API_KEY=user_provided
          # ANTHROPIC_MODELS=claude-3-5-sonnet-20240620,claude-3-opus-20240229,claude-3-sonnet-20240229,claude-3-haiku-20240307,claude-2.1,claude-2,claude-1.2,claude-1,claude-1-100k,claude-instant-1,claude-instant-1-100k
          # ANTHROPIC_REVERSE_PROXY=


          #============#
          # Google     #
          #============#

          # GOOGLE_KEY=user_provided
          # GOOGLE_REVERSE_PROXY=

          # Gemini API (AI Studio)
          # GOOGLE_MODELS=gemini-1.5-flash-latest,gemini-1.0-pro,gemini-1.0-pro-001,gemini-1.0-pro-latest,gemini-1.0-pro-vision-latest,gemini-1.5-pro-latest,gemini-pro,gemini-pro-vision

          # Vertex AI
          # GOOGLE_MODELS=gemini-1.5-flash-preview-0514,gemini-1.5-pro-preview-0514,gemini-1.0-pro-vision-001,gemini-1.0-pro-002,gemini-1.0-pro-001,gemini-pro-vision,gemini-1.0-pro

          # GOOGLE_TITLE_MODEL=gemini-pro

          # Google Safety Settings
          # NOTE: These settings apply to both Vertex AI and Gemini API (AI Studio)
          #
          # For Vertex AI:
          # To use the BLOCK_NONE setting, you need either:
          # (a) Access through an allowlist via your Google account team, or
          # (b) Switch to monthly invoiced billing: https://cloud.google.com/billing/docs/how-to/invoiced-billing
          #
          # For Gemini API (AI Studio):
          # BLOCK_NONE is available by default, no special account requirements.
          #
          # Available options: BLOCK_NONE, BLOCK_ONLY_HIGH, BLOCK_MEDIUM_AND_ABOVE, BLOCK_LOW_AND_ABOVE
          #
          # GOOGLE_SAFETY_SEXUALLY_EXPLICIT=BLOCK_ONLY_HIGH
          # GOOGLE_SAFETY_HATE_SPEECH=BLOCK_ONLY_HIGH
          # GOOGLE_SAFETY_HARASSMENT=BLOCK_ONLY_HIGH
          # GOOGLE_SAFETY_DANGEROUS_CONTENT=BLOCK_ONLY_HIGH

          #============#
          # OpenAI     #
          #============#

          OPENAI_API_KEY={{ api_keys.openai }}
          OPENAI_MODELS=chatgpt-4o-latest,gpt-4o,gpt-4o-mini,gpt-4-turbo,o1-mini

          DEBUG_OPENAI=false

          # TITLE_CONVO=false
          OPENAI_TITLE_MODEL=gpt-4o-mini

          OPENAI_SUMMARIZE=true
          OPENAI_SUMMARY_MODEL=gpt-4o-mini

          # OPENAI_FORCE_PROMPT=true

          # OPENAI_REVERSE_PROXY=

          # OPENAI_ORGANIZATION=

          #====================#
          #   Assistants API   #
          #====================#

          # ASSISTANTS_API_KEY=user_provided
          # ASSISTANTS_BASE_URL=
          # ASSISTANTS_MODELS=gpt-4o,gpt-4o-mini,gpt-3.5-turbo-0125,gpt-3.5-turbo-16k-0613,gpt-3.5-turbo-16k,gpt-3.5-turbo,gpt-4,gpt-4-0314,gpt-4-32k-0314,gpt-4-0613,gpt-3.5-turbo-0613,gpt-3.5-turbo-1106,gpt-4-0125-preview,gpt-4-turbo-preview,gpt-4-1106-preview

          #==========================#
          #   Azure Assistants API   #
          #==========================#

          # Note: You should map your credentials with custom variables according to your Azure OpenAI Configuration
          # The models for Azure Assistants are also determined by your Azure OpenAI configuration.

          # More info, including how to enable use of Assistants with Azure here:
          # https://www.librechat.ai/docs/configuration/librechat_yaml/ai_endpoints/azure#using-assistants-with-azure

          #============#
          # OpenRouter #
          #============#
          # !!!Warning: Use the variable above instead of this one. Using this one will override the OpenAI endpoint
          # OPENROUTER_API_KEY=

          #============#
          # Plugins    #
          #============#

          PLUGIN_MODELS=chatgpt-4o-latest,gpt-4o,gpt-4o-mini,gpt-4-turbo,o1-mini

          DEBUG_PLUGINS=true

          CREDS_KEY={{ stacks.ai.env.CREDS_KEY }}
          CREDS_IV={{ stacks.ai.env.CREDS_IV }}

          # DALL·E
          #----------------
          # DALLE_API_KEY=
          # DALLE3_API_KEY=
          # DALLE2_API_KEY=
          # DALLE3_SYSTEM_PROMPT=
          # DALLE2_SYSTEM_PROMPT=
          # DALLE_REVERSE_PROXY=
          # DALLE3_BASEURL=
          # DALLE2_BASEURL=

          # DALL·E (via Azure OpenAI)
          # Note: requires some of the variables above to be set
          #----------------
          # DALLE3_AZURE_API_VERSION=
          # DALLE2_AZURE_API_VERSION=

          # Google
          #-----------------
          # GOOGLE_SEARCH_API_KEY=
          # GOOGLE_CSE_ID=

          # SerpAPI
          #-----------------
          SERPAPI_API_KEY=

          # Stable Diffusion
          #-----------------
          SD_WEBUI_URL=http://host.docker.internal:7860

          # Tavily
          #-----------------
          # TAVILY_API_KEY=

          # Traversaal
          #-----------------
          # TRAVERSAAL_API_KEY=

          # WolframAlpha
          #-----------------
          # WOLFRAM_APP_ID=

          # Zapier
          #-----------------
          # ZAPIER_NLA_API_KEY=

          #==================================================#
          #                      Search                      #
          #==================================================#

          SEARCH=true
          MEILI_NO_ANALYTICS=true
          MEILI_HOST=http://0.0.0.0:7700
          MEILI_MASTER_KEY={{ stacks.ai.env.MEILI_MASTER_KEY }}

          #==================================================#
          #          Speech to Text & Text to Speech         #
          #==================================================#

          STT_API_KEY={{ api_keys.openai }}
          TTS_API_KEY={{ api_keys.openai }}

          #==================================================#
          #                        RAG                       #
          #==================================================#
          # More info: https://www.librechat.ai/docs/configuration/rag_api

          # RAG_OPENAI_BASEURL=
          # RAG_OPENAI_API_KEY=
          # EMBEDDINGS_PROVIDER=openai
          # EMBEDDINGS_MODEL=text-embedding-3-small

          #===================================================#
          #                    User System                    #
          #===================================================#

          #========================#
          # Moderation             #
          #========================#

          OPENAI_MODERATION=false
          OPENAI_MODERATION_API_KEY=
          # OPENAI_MODERATION_REVERSE_PROXY=

          BAN_VIOLATIONS=true
          BAN_DURATION=1000 * 60 * 60 * 2
          BAN_INTERVAL=20

          LOGIN_VIOLATION_SCORE=1
          REGISTRATION_VIOLATION_SCORE=1
          CONCURRENT_VIOLATION_SCORE=1
          MESSAGE_VIOLATION_SCORE=1
          NON_BROWSER_VIOLATION_SCORE=20

          LOGIN_MAX=7
          LOGIN_WINDOW=5
          REGISTER_MAX=5
          REGISTER_WINDOW=60

          LIMIT_CONCURRENT_MESSAGES=true
          CONCURRENT_MESSAGE_MAX=2

          LIMIT_MESSAGE_IP=true
          MESSAGE_IP_MAX=40
          MESSAGE_IP_WINDOW=1

          LIMIT_MESSAGE_USER=false
          MESSAGE_USER_MAX=40
          MESSAGE_USER_WINDOW=1

          ILLEGAL_MODEL_REQ_SCORE=5

          #========================#
          # Balance                #
          #========================#

          CHECK_BALANCE=false

          #========================#
          # Registration and Login #
          #========================#

          ALLOW_EMAIL_LOGIN=true
          ALLOW_REGISTRATION=false
          ALLOW_SOCIAL_LOGIN=true
          ALLOW_SOCIAL_REGISTRATION=true
          ALLOW_PASSWORD_RESET=true
          # ALLOW_ACCOUNT_DELETION=true # note: enabled by default if omitted/commented out
          ALLOW_UNVERIFIED_EMAIL_LOGIN=true

          SESSION_EXPIRY=1000 * 60 * 15
          REFRESH_TOKEN_EXPIRY=(1000 * 60 * 60 * 24) * 7

          JWT_SECRET={{ stacks.ai.env.JWT_SECRET }}
          JWT_REFRESH_SECRET={{ stacks.ai.env.JWT_REFRESH_SECRET }}

          # OpenID
          OPENID_ISSUER=https://auth.rusanov.cloud/application/o/librechat/.well-known/openid-configuration
          OPENID_CLIENT_ID={{ stacks.ai.env.OPENID_CLIENT_ID }}
          OPENID_CLIENT_SECRET={{ stacks.ai.env.OPENID_CLIENT_ID }}
          OPENID_SESSION_SECRET={{ stacks.ai.env.OPENID_SESSION_SECRET }}
          OPENID_CALLBACK_URL=/oauth/openid/callback
          OPENID_SCOPE="openid profile email"
          # OPENID_REQUIRED_ROLE=user
          # OPENID_REQUIRED_ROLE_TOKEN_KIND=
          # OPENID_REQUIRED_ROLE_PARAMETER_PATH=

          # OPENID_BUTTON_LABEL=Authentik
          # OPENID_IMAGE_URL=

          #========================#
          # Email Password Reset   #
          #========================#

          EMAIL_HOST="{{ smtp.host }}"
          EMAIL_PORT="{{ smtp.port }}"
          EMAIL_ENCRYPTION=tls
          EMAIL_ALLOW_SELFSIGNED=true
          EMAIL_USERNAME="{{ smtp.user }}"
          EMAIL_PASSWORD="{{ smtp.password }}"
          EMAIL_FROM_NAME="{{ smtp.from_name }}"
          EMAIL_FROM="{{ smtp.from }}"

          #========================#
          # Shared Links           #
          #========================#

          ALLOW_SHARED_LINKS=true
          ALLOW_SHARED_LINKS_PUBLIC=false

          #==============================#
          # Static File Cache Control    #
          #==============================#

          # Leave commented out to use defaults: 1 day (86400 seconds) for s-maxage and 2 days (172800 seconds) for max-age
          # NODE_ENV must be set to production for these to take effect
          # STATIC_CACHE_MAX_AGE=172800
          # STATIC_CACHE_S_MAX_AGE=86400

          # If you have another service in front of your LibreChat doing compression, disable express based compression here
          DISABLE_COMPRESSION=true

          #===================================================#
          #                        UI                         #
          #===================================================#

          APP_TITLE=LibreChat
          # CUSTOM_FOOTER="My custom footer"
          HELP_AND_FAQ_URL=https://librechat.ai

          # SHOW_BIRTHDAY_ICON=true

          POSTGRES_DB=librechat_vector
          POSTGRES_USER=pgvector
          POSTGRES_PASSWORD={{ stacks.ai.env.POSTGRES_PASSWORD }}
        dest: /root/stacks/ai/.env

    - name: Deploy AI stack from a compose file
      community.docker.docker_stack:
        state: present
        name: ai
        compose:
          - /root/stacks/ai/compose.yaml
